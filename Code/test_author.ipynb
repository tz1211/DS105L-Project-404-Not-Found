{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## this is for testing usage only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import news data and season duration\n",
    "df_season = pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/season_duration.csv')\n",
    "df_nba_news_archive = pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_news_archive.csv')\n",
    "df_nba_news_archive_600 = pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_news_archive_600.csv')\n",
    "df_nba_news_archive_600_1200 = pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_news_archive_600_1200.csv')\n",
    "df_nba_news_archive_1200_1640 = pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_news_archive_1200_1640.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_0 = df_nba_news_archive.copy()\n",
    "news_600 = df_nba_news_archive_600.copy()\n",
    "news_600_1200 = df_nba_news_archive_600_1200.copy()\n",
    "news_1200_1600 = df_nba_news_archive_1200_1640.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def find_author(df_news):\n",
    "    list_url = list(df_news[\"url\"])\n",
    "    author_list = []\n",
    "    for url in tqdm(list_url, desc=\"Finding authors\"):\n",
    "        try:\n",
    "            r = requests.get(url) \n",
    "            soup = BeautifulSoup(r.content, \"html.parser\") \n",
    "            author = soup.find(\"span\", attrs ={\"class\": \"entry-header__author\"}).contents[0]\n",
    "            author_list.append(author)\n",
    "        except:\n",
    "            author = \"NA\"\n",
    "            author_list.append(author)\n",
    "    df_news.loc[:, \"author\"] = author_list\n",
    "    return df_news\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "This event loop is already running",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb Cell 5\u001b[0m in \u001b[0;36m<cell line: 44>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb#X16sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Run the asynchronous function to get the authors\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb#X16sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m loop \u001b[39m=\u001b[39m asyncio\u001b[39m.\u001b[39mget_event_loop()\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb#X16sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m author_list \u001b[39m=\u001b[39m loop\u001b[39m.\u001b[39;49mrun_until_complete(find_authors(url_list))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb#X16sZmlsZQ%3D%3D?line=44'>45</a>\u001b[0m loop\u001b[39m.\u001b[39mclose()\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb#X16sZmlsZQ%3D%3D?line=46'>47</a>\u001b[0m \u001b[39m# Add the authors to the dataframe\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/asyncio/base_events.py:623\u001b[0m, in \u001b[0;36mBaseEventLoop.run_until_complete\u001b[0;34m(self, future)\u001b[0m\n\u001b[1;32m    612\u001b[0m \u001b[39m\"\"\"Run until the Future is done.\u001b[39;00m\n\u001b[1;32m    613\u001b[0m \n\u001b[1;32m    614\u001b[0m \u001b[39mIf the argument is a coroutine, it is wrapped in a Task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    620\u001b[0m \u001b[39mReturn the Future's result, or raise its exception.\u001b[39;00m\n\u001b[1;32m    621\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    622\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_closed()\n\u001b[0;32m--> 623\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_check_running()\n\u001b[1;32m    625\u001b[0m new_task \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m futures\u001b[39m.\u001b[39misfuture(future)\n\u001b[1;32m    626\u001b[0m future \u001b[39m=\u001b[39m tasks\u001b[39m.\u001b[39mensure_future(future, loop\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/asyncio/base_events.py:583\u001b[0m, in \u001b[0;36mBaseEventLoop._check_running\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    581\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_check_running\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m    582\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_running():\n\u001b[0;32m--> 583\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mThis event loop is already running\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    584\u001b[0m     \u001b[39mif\u001b[39;00m events\u001b[39m.\u001b[39m_get_running_loop() \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    585\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    586\u001b[0m             \u001b[39m'\u001b[39m\u001b[39mCannot run the event loop while another loop is running\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: This event loop is already running"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import asyncio\n",
    "import aiohttp\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "\n",
    "async def get_html(url):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        async with session.get(url) as response:\n",
    "            return await response.text()\n",
    "\n",
    "\n",
    "async def get_author(html):\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "    author = soup.find(\"span\", {\"class\": \"c-byline__item\"})\n",
    "    if author is not None:\n",
    "        return author.get_text().strip()\n",
    "    else:\n",
    "        return \"N/A\"\n",
    "\n",
    "\n",
    "async def find_authors(url_list):\n",
    "    tasks = []\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        for url in url_list:\n",
    "            tasks.append(get_html(url))\n",
    "        html_list = await asyncio.gather(*tasks)\n",
    "    tasks = []\n",
    "    for html in html_list:\n",
    "        tasks.append(get_author(html))\n",
    "    author_list = await asyncio.gather(*tasks)\n",
    "    return author_list\n",
    "\n",
    "\n",
    "# Load the news dataset\n",
    "# Keep the first 500 rows of data for testing purposes\n",
    "df_news = news_0[:500]\n",
    "\n",
    "# Create a list of URLs\n",
    "url_list = df_news.url.tolist()\n",
    "\n",
    "# Run the asynchronous function to get the authors\n",
    "loop = asyncio.get_event_loop()\n",
    "author_list = loop.run_until_complete(find_authors(url_list))\n",
    "loop.close()\n",
    "\n",
    "# Add the authors to the dataframe\n",
    "df_news['author'] = author_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>title</th>\n",
       "      <th>time</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Bucksâ€™ George Hill Returns To Milwaukee, Encou...</td>\n",
       "      <td>October 24, 2020</td>\n",
       "      <td>http://global.nba.com/news/bucks-george-hill-r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NBA, WNBA Ramp Up Efforts To Get Out The Vote ...</td>\n",
       "      <td>October 24, 2020</td>\n",
       "      <td>http://global.nba.com/news/nba-wnba-ramp-up-ef...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Pat Riley Discusses Heat Future, Plans For Kee...</td>\n",
       "      <td>October 23, 2020</td>\n",
       "      <td>http://global.nba.com/news/pat-riley-discusses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Report: Amarâ€™e Stoudemire Joins Steve Nashâ€™s C...</td>\n",
       "      <td>October 23, 2020</td>\n",
       "      <td>http://global.nba.com/news/report-amare-stoude...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>ESPN To Host Virtual 2020 NBA Draft Presented ...</td>\n",
       "      <td>October 22, 2020</td>\n",
       "      <td>http://global.nba.com/news/espn-to-host-virtua...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>495</td>\n",
       "      <td>McCollumâ€™s Clutch Performance Gives Blazers Co...</td>\n",
       "      <td>August 15, 2020</td>\n",
       "      <td>http://global.nba.com/news/mccollums-clutch-pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>496</td>\n",
       "      <td>Blazers Make Playoffs, Oust Grizzlies With 126...</td>\n",
       "      <td>August 15, 2020</td>\n",
       "      <td>http://global.nba.com/news/blazers-make-playof...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>497</td>\n",
       "      <td>Jusuf Nurkicâ€™s Grandmother Has Died From COVID-19</td>\n",
       "      <td>August 15, 2020</td>\n",
       "      <td>http://global.nba.com/news/jusuf-nurkics-grand...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>498</td>\n",
       "      <td>Portlandâ€™s Lillard Named KIA NBA Player Of The...</td>\n",
       "      <td>August 15, 2020</td>\n",
       "      <td>http://global.nba.com/news/portlands-lillard-n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>499</td>\n",
       "      <td>Pelicans Dismiss Coach Alvin Gentry</td>\n",
       "      <td>August 15, 2020</td>\n",
       "      <td>http://global.nba.com/news/pelicans-dismiss-co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0                                              title  \\\n",
       "0             0  Bucksâ€™ George Hill Returns To Milwaukee, Encou...   \n",
       "1             1  NBA, WNBA Ramp Up Efforts To Get Out The Vote ...   \n",
       "2             2  Pat Riley Discusses Heat Future, Plans For Kee...   \n",
       "3             3  Report: Amarâ€™e Stoudemire Joins Steve Nashâ€™s C...   \n",
       "4             4  ESPN To Host Virtual 2020 NBA Draft Presented ...   \n",
       "..          ...                                                ...   \n",
       "495         495  McCollumâ€™s Clutch Performance Gives Blazers Co...   \n",
       "496         496  Blazers Make Playoffs, Oust Grizzlies With 126...   \n",
       "497         497  Jusuf Nurkicâ€™s Grandmother Has Died From COVID-19   \n",
       "498         498  Portlandâ€™s Lillard Named KIA NBA Player Of The...   \n",
       "499         499                Pelicans Dismiss Coach Alvin Gentry   \n",
       "\n",
       "                 time                                                url  \n",
       "0    October 24, 2020  http://global.nba.com/news/bucks-george-hill-r...  \n",
       "1    October 24, 2020  http://global.nba.com/news/nba-wnba-ramp-up-ef...  \n",
       "2    October 23, 2020  http://global.nba.com/news/pat-riley-discusses...  \n",
       "3    October 23, 2020  http://global.nba.com/news/report-amare-stoude...  \n",
       "4    October 22, 2020  http://global.nba.com/news/espn-to-host-virtua...  \n",
       "..                ...                                                ...  \n",
       "495   August 15, 2020  http://global.nba.com/news/mccollums-clutch-pe...  \n",
       "496   August 15, 2020  http://global.nba.com/news/blazers-make-playof...  \n",
       "497   August 15, 2020  http://global.nba.com/news/jusuf-nurkics-grand...  \n",
       "498   August 15, 2020  http://global.nba.com/news/portlands-lillard-n...  \n",
       "499   August 15, 2020  http://global.nba.com/news/pelicans-dismiss-co...  \n",
       "\n",
       "[500 rows x 4 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_0_author = find_author(news_0[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'author_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/annabelitong/Desktop/Annabel/uni/DS105L/group_project/DS105L-Project/Code/test_author.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m author_list\n",
      "\u001b[0;31mNameError\u001b[0m: name 'author_list' is not defined"
     ]
    }
   ],
   "source": [
    "author_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87    http://global.nba.com/news/report-bam-adebayo-...\n",
       "Name: url, dtype: object"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_0[87:88][\"url\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "credit_article = []\n",
    "credit_followers = []\n",
    "credit_tweets = []\n",
    "for names in list(news_0_author[\"author\"]):\n",
    "    if names == \"NA\":\n",
    "        credit_article.append(names)\n",
    "        credit_followers.append(names)\n",
    "        credit_tweets.append(names)\n",
    "    elif \"NBA.com\" in names or \"NBA News\" in names or \"Press\" in names or \"Official Release\" in names or \"NBA Twitter\" in names:\n",
    "        credit_article.append(\"Default\")\n",
    "        credit_followers.append(\"Default\")\n",
    "        credit_tweets.append(\"Default\")\n",
    "    else:\n",
    "        try:\n",
    "            player_search = names.replace(\" \", \"-\")\n",
    "            url = \"https://muckrack.com/\" + player_search\n",
    "            response = requests.get(url)\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            html = soup.find_all('a', attrs={'class':\"profile-edit-btn\"})\n",
    "            if len(html) == 0:\n",
    "                num_articles = \"none\"\n",
    "                credit_article.append(num_articles)\n",
    "            else:\n",
    "            \n",
    "                for line in html:\n",
    "                        if \"See all\" in line.text:\n",
    "                            span_elem = line.find('span')\n",
    "                            text_content = span_elem.text.strip()\n",
    "                            num_articles = text_content.split()[0].replace(',', '')\n",
    "                            credit_article.append(num_articles)\n",
    "                            break\n",
    "\n",
    "            tweet = soup.find_all('p', attrs={'class':\"fs-6 mt-0 mb-6\"})\n",
    "            tweet_num = tweet.get_all(\"strong\")\n",
    "            followers = tweet_num[0].strong.text.replace(',', '')\n",
    "            tweets = tweet_num[1].strong.text.replace(',', '')\n",
    "\n",
    "        except:\n",
    "            if len(credit_followers) < len(credit_article):\n",
    "                credit_followers.append(\"None\")\n",
    "            if len(credit_tweets) < len(credit_article):\n",
    "                credit_tweets.append(\"None\")\n",
    "\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Default',\n",
       " 'Default',\n",
       " 'none',\n",
       " '618',\n",
       " '199',\n",
       " 'Default',\n",
       " 'Default',\n",
       " 'NA',\n",
       " 'none',\n",
       " 'Default',\n",
       " 'Default',\n",
       " 'Default',\n",
       " 'Default',\n",
       " 'NA',\n",
       " '618',\n",
       " 'Default',\n",
       " 'none',\n",
       " 'Default',\n",
       " 'none',\n",
       " 'Default']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://twitter.com/search?q=Steve%20Aschburner&src=typed_query&f=user\"\n",
    "r = requests.get(url)\n",
    "soup =BeautifulSoup(r.text, 'html.parser')\n",
    "html = soup.find('div', attrs={'class':\"css-1dbjc4n r-1wbh5a2 r-dnmrzs r-1ny4l3l\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "html"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "705d6f4ecb8a535ad130d19f33aca7c81049a16c0faf5a3ee87de4e6b987140d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
