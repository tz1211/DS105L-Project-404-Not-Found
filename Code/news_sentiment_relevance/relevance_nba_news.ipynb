{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# key words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df600= pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_author_credit/nba_600_credit_season_3.csv')\n",
    "df1200= pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_author_credit/nba_1200_credit_season_3.csv')\n",
    "df1600= pd.read_csv('/Users/annabelitong/desktop/annabel/uni/ds105l/group_project/DS105L-Project/Data/nba_author_credit/nba_1600_credit_season_3.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nba_content(url):\n",
    "    r = requests.get(url)\n",
    "    soup = BeautifulSoup(r.content, \"html.parser\")\n",
    "    content = soup.find(\"div\", attrs={\"class\": \"entry__content entry-content\"})\n",
    "\n",
    "    if content is None:\n",
    "        return None\n",
    "\n",
    "    main_body = content.find_all('p')\n",
    "    text = \" \".join([p.get_text(strip=True) for p in main_body])\n",
    "    clean_text = text.replace('\\n', ' ').replace('\\xa0', '')\n",
    "    return clean_text\n",
    "\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()     # Convert text to lowercase\n",
    "    \n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text) # Remove punctuation and special characters\n",
    "    \n",
    "    words = nltk.word_tokenize(text)     # Tokenize the text into words\n",
    "\n",
    "    stop_words = set(stopwords.words(\"english\"))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    preprocessed_text = \" \".join(words)\n",
    "    \n",
    "    return preprocessed_text\n",
    "\n",
    "def assess_nba_relevance(df):\n",
    "    relevance_scores = []\n",
    "    \n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        content = get_nba_content(row['url'])\n",
    "        player_name = row['player']\n",
    "        if content is None:\n",
    "            relevance_scores.append(0)\n",
    "            continue\n",
    "        preprocessed_content = preprocess_text(content)\n",
    "        \n",
    "        statement = player_name + \" will be the MVP\"\n",
    "        statement_keywords = statement.lower().split()\n",
    "        \n",
    "        relevance_score = 0\n",
    "        \n",
    "        for keyword in statement_keywords:\n",
    "            if keyword in preprocessed_content:\n",
    "                relevance_score += 0.2\n",
    "        \n",
    "        # Check if player name is mentioned\n",
    "        if player_name.lower() in preprocessed_content:\n",
    "            relevance_score += 0.2\n",
    "        \n",
    "        relevance_scores.append(relevance_score)\n",
    "    \n",
    "    df['key_words_score'] = relevance_scores\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "705d6f4ecb8a535ad130d19f33aca7c81049a16c0faf5a3ee87de4e6b987140d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
